#!/usr/bin/env python3
"""
Create comprehensive redirects for stuartgeiger.com migration
Handles both duplicate files and legacy URL patterns
"""

import os
import json
from pathlib import Path

def create_netlify_redirects():
    """Create _redirects file for Netlify hosting"""
    
    # Load duplicate redirects
    with open('duplicate_redirects.json', 'r') as f:
        duplicates = json.load(f)
    
    redirects = []
    
    # Add duplicate file redirects
    for old_path, new_path in duplicates.items():
        redirects.append(f"/{old_path} /{new_path} 301")
    
    # Add legacy URL pattern redirects
    legacy_patterns = [
        # Old paper URLs to new files location
        "/papers/*.pdf /files/:splat.pdf 301",
        "/portfolio/papers/*.pdf /files/:splat.pdf 301",
        
        # WordPress legacy redirects (already handled by jekyll-redirect-from but good to have)
        "/wordpress/* / 301",
        
        # Common CV locations
        "/geiger-cv.pdf /files/geiger-cv.pdf 301",
        "/cv.pdf /files/geiger-cv.pdf 301",
        
        # Old asset locations
        "/wikimania-geiger-conceptions.ppt /assets/wikimania-geiger-conceptions.ppt 301",
    ]
    
    # Write Netlify redirects file
    with open('_redirects', 'w') as f:
        f.write("# Netlify redirects for stuartgeiger.com\n")
        f.write("# Generated by create_redirects.py\n\n")
        
        f.write("# Duplicate file redirects\n")
        for redirect in redirects:
            f.write(redirect + "\n")
        
        f.write("\n# Legacy URL pattern redirects\n")
        for pattern in legacy_patterns:
            f.write(pattern + "\n")
    
    print(f"Created _redirects file with {len(redirects)} duplicate redirects and {len(legacy_patterns)} pattern redirects")

def create_htaccess_redirects():
    """Create .htaccess file for Apache hosting"""
    
    # Load duplicate redirects
    with open('duplicate_redirects.json', 'r') as f:
        duplicates = json.load(f)
    
    htaccess_rules = []
    
    # Add duplicate file redirects
    for old_path, new_path in duplicates.items():
        htaccess_rules.append(f"Redirect 301 /{old_path} /{new_path}")
    
    # Write .htaccess file
    with open('.htaccess', 'w') as f:
        f.write("# Apache redirects for stuartgeiger.com\n")
        f.write("# Generated by create_redirects.py\n\n")
        
        f.write("# Enable redirect module\n")
        f.write("RewriteEngine On\n\n")
        
        f.write("# Duplicate file redirects\n")
        for rule in htaccess_rules:
            f.write(rule + "\n")
        
        f.write("\n# Legacy URL pattern redirects\n")
        f.write("RedirectMatch 301 ^/papers/(.*\\.pdf)$ /files/$1\n")
        f.write("RedirectMatch 301 ^/portfolio/papers/(.*\\.pdf)$ /files/$1\n")
        f.write("Redirect 301 /geiger-cv.pdf /files/geiger-cv.pdf\n")
        f.write("Redirect 301 /cv.pdf /files/geiger-cv.pdf\n")
    
    print(f"Created .htaccess file with {len(htaccess_rules)} redirect rules")

def update_publication_urls():
    """Update publication front matter to use local files instead of external URLs"""
    
    publications_dir = Path('_publications')
    updated_count = 0
    
    for pub_file in publications_dir.glob('*.md'):
        with open(pub_file, 'r') as f:
            content = f.read()
        
        # Check if it has an external paperurl
        if 'paperurl: http' in content:
            lines = content.split('\n')
            new_lines = []
            
            for line in lines:
                if line.startswith('paperurl:'):
                    url = line.split('paperurl:')[1].strip()
                    
                    # Check if it's pointing to stuartgeiger.com
                    if 'stuartgeiger.com' in url:
                        # Extract filename
                        filename = url.split('/')[-1]
                        
                        # Check if we have this file locally
                        if Path(f'files/{filename}').exists():
                            new_lines.append(f'paperurl: /files/{filename}')
                            print(f"Updated {pub_file.name}: {url} -> /files/{filename}")
                            updated_count += 1
                        else:
                            new_lines.append(line)
                    else:
                        new_lines.append(line)
                else:
                    new_lines.append(line)
            
            # Write back if changed
            new_content = '\n'.join(new_lines)
            if new_content != content:
                with open(pub_file, 'w') as f:
                    f.write(new_content)
    
    print(f"\nUpdated {updated_count} publication URLs to use local files")

def main():
    os.chdir('/home/jupyter-staeiou/academicpages.github.io')
    
    print("Creating redirect configurations...")
    create_netlify_redirects()
    create_htaccess_redirects()
    
    print("\nUpdating publication URLs...")
    update_publication_urls()
    
    print("\nDone! Next steps:")
    print("1. Review the generated _redirects (Netlify) or .htaccess (Apache) file")
    print("2. Remove duplicate files if desired (see duplicate_redirects.json)")
    print("3. Commit and deploy to stuartgeiger.com")

if __name__ == "__main__":
    main()